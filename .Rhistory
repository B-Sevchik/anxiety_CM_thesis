write_csv(illegal_df, 'data/illegalTransition.csv')
acc_illegal_df <- illegal_df %>%
select(subject, transitionType, acc, transitionThreatKind) %>%
group_by(transitionType, acc)
transition_type_df <- acc_illegal_df %>%
mutate(acc_descriptor = case_when(
(transitionType == 'i' & acc == 1) ~ "hits",
(transitionType == 'i' & acc == 0) ~ "misses",
(transitionType == 'l' & acc == 0) ~ "false_alarms",
(transitionType == 'l' & acc == 1) ~ "correct_rejections"
))
transition_type_df <- transition_type_df %>%
mutate(transition_threat = case_when(
(transitionThreatKind == 'threat-threat' | transitionThreatKind == 'threat-neutral' | transitionThreatKind == 'neutral-threat') ~ "contains_threat",
(transitionThreatKind == 'neutral-neutral') ~ "no_threat"
))
write_csv(transition_type_df, 'data/transitionType.csv')
counts_transitionType_df <- transition_type_df %>%
group_by(subject, acc_descriptor, transition_threat) %>%
summarize(count = n()) %>%
pivot_wider(names_from = acc_descriptor, values_from = count, values_fill = 0)
write_csv(counts_transitionType_df, 'data/counts_transitionType.csv')
dprime_df <- counts_transitionType_df
dprime.stats <-psycho::dprime(counts_transitionType_df$hits, counts_transitionType_df$false_alarms, counts_transitionType_df$misses, counts_transitionType_df$correct_rejections)
dprime_df$dprime <- dprime.stats$dprime
write_csv(dprime_df, 'data/dprime.csv')
excluded_illegal_subs <- dprime_df %>%
filter(dprime < 0.3573812)
#ODD ONE OUT TASK exclude anyone below 40% accuracy
ooo_df <- df %>%
filter(taskName == "oddOneOutTest") %>%
select(subject, trialCount, RT, acc, partResp, chosenNode:chosenThreatStatus,
option1CommunityNumber, option1ThreatStatus,
option2CommunityNumber, option2ThreatStatus,
option3CommunityNumber, option3ThreatStatus)
write_csv(ooo_df, 'data/OddOneOut.csv')
ooo_acc <- ooo_df %>%
group_by(subject) %>%
summarise(acc = mean(acc, na.rm = TRUE))
write_csv(ooo_acc, 'data/OOOAcc.csv')
excluded_ooo_subs <- ooo_acc %>%
filter(acc < 0.4)
#JOIN EXCLUDED SUBS DATA FRAMES
excluded_subjects <- excluded_drag_subjects %>%
full_join(excluded_illegal_subs, by="subject") %>%
full_join(excluded_ooo_subs, by="subject") %>%
select(subject)
write_csv(excluded_subjects, 'data/excludedSubjects.csv')
#DEMOGRAPHICS
library(readr)
library(dplyr)
demos <- read_csv('/Users/brookesevchik/Box/Data/Anxiety_Cognitive_Maps/all_participants/SubjectInfo.csv')
# Filter the demos data frame to exclude the specified subjects
demos <- demos %>%
filter(!workerID %in% excluded_subjects$subject)
# Define the function to get demographic information
get_sub_info <- function(demos) {
cat("Sex\n")
cat(paste('F: ', sum(demos$Gender == 'F', na.rm = TRUE), sep = ""), "\n")
cat(paste('M: ', sum(demos$Gender == 'M', na.rm = TRUE), sep = ""), "\n")
cat("Age\n")
cat(paste('Min: ', min(demos$Age, na.rm = TRUE), sep = ""), "\n")
cat(paste('Max: ', max(demos$Age, na.rm = TRUE), sep = ""), "\n")
cat(paste('Mean: ', mean(demos$Age, na.rm = TRUE), sep = ""), "\n")
cat(paste('SD: ', sd(demos$Age, na.rm = TRUE), sep = ""), "\n")
}
# Call the function to get demographic information
get_sub_info(demos)
write_csv(demos, 'data/demographics.csv')
#set-up
setwd("~/Documents/GitHub/anxiety_CM_thesis")
library(tidyverse)
library(dplyr)
#BE SURE TO EDIT PATH NAMES EACH TIME YOU RUN SCRIPT
#path references
data_path <- '/Users/brookesevchik/Box/Data/Anxiety_Cognitive_Maps/all_participants/STAIscores.csv' #EDIT PATH NAME EACH TIME
#load data
STAI_df <- read_csv(data_path)
#manipulate df into proper format
colnames(STAI_df) <- c('not_included', 'subjectID', paste0('s', 1:20))
num_rows = nrow(STAI_df)
num_rows
STAI_df <- STAI_df %>%
slice(2:num_rows) %>%
select('subjectID', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20')
#getting STAI scores into numeric form
STAI_df <- transform(STAI_df,s1 = as.numeric(s1))
STAI_df <- STAI_df %>%
mutate(across(paste0('s', 1:20), as.numeric))
#changing non-responses (5) into NaN
STAI_df <- STAI_df %>%
mutate(across(paste0('s', 1:20), ~ case_when(. == 5 ~ 0,
TRUE ~ .)))
#reverse score what needs to be reverse scored
STAI_df <- STAI_df %>%
group_by(subjectID) %>%
mutate(s1 = ifelse(s1== 0, 0, 5 - s1),
s3 = ifelse(s3== 0, 0, 5 - s3),
s6 = ifelse(s6== 0, 0, 5 - s6),
s7 = ifelse(s7== 0, 0, 5 - s7),
s10 = ifelse(s10== 0, 0, 5 - s10),
s13 = ifelse(s13== 0, 0, 5 - s13),
s14 = ifelse(s14== 0, 0, 5 - s14),
s16 = ifelse(s16== 0, 0, 5 - s16),
s19 = ifelse(s19== 0, 0, 5 - s19))
#get the mean & replace NaNs(0s) w the mean
STAI_df <- STAI_df %>%
mutate(meanVals = (s1 + s2 + s3 + s4 + s5 + s6 + s7 + s8 + s9 + s10 + s11 + s12 + s13 + s14 + s15 + s16 + s17 + s18 + s19 + s20)/ 20) %>%
mutate(across(paste0('s', 1:20), ~ case_when(. == 0 ~ meanVals,
TRUE ~ .)))
#sum STAI score
STAI_df <-STAI_df %>%
group_by(subjectID) %>%
mutate(sumVals = s1 + s2 + s3 + s4 + s5 + s6 + s7 + s8 + s9 + s10 + s11 + s12 + s13 + s14 + s15 + s16 + s17 + s18 + s19 + s20)
#classify anxiety levels based on STAI sum
STAI_df <- STAI_df %>%
group_by(subjectID) %>%
mutate(anxiety_level = case_when(
sumVals <= 37 ~ 'low trait anxiety',
sumVals >= 38 & sumVals < 44 ~ 'moderate trait anxiety',
sumVals >= 44 ~ 'high trait anxiety'
))
STAI_df
#save out the file
write.csv(STAI_df, 'data/STAI.csv')
write.csv(STAI_df, '/Users/brookesevchik/Box/Data/Anxiety_Cognitive_Maps/all_participants/STAI_scores_calculated.csv') #EDIT PATH NAME EACH TIME
library(plotrix)
df <- read_csv('/Users/brookesevchik/Box/Data/Anxiety_Cognitive_Maps/all_participants/combinedData_Anxiety_Cognitive_Maps.csv')
check_answer_df <- df %>%
filter(sectionType == 'dragTaskCheckAnswerEvent') %>%
select(subject, trialCount, trialAttempt, RT, nCorrect, slot0Acc, slot0CurrentType, slot0CorrectType, slot0CurrentSRC, slot0CorrectSRC, slot1Acc,
slot1CurrentType, slot1CorrectType,slot1CurrentSRC, slot1CorrectSRC,
slot2Acc, slot2CurrentType, slot2CorrectType, slot2CurrentSRC, slot2CorrectSRC,
slot3Acc, slot3CurrentType, slot3CorrectType, slot3CurrentSRC, slot3CorrectSRC,
slot4Acc, slot4CurrentType, slot4CorrectType, slot4CurrentSRC, slot4CorrectSRC,
slot5Acc, slot5CurrentType, slot5CorrectType, slot5CurrentSRC, slot5CorrectSRC,
slot6Acc, slot6CurrentType, slot6CorrectType, slot6CurrentSRC, slot6CorrectSRC,
slot7Acc, slot7CurrentType, slot7CorrectType, slot7CurrentSRC, slot7CorrectSRC,
slot8Acc, slot8CurrentType, slot8CorrectType, slot8CurrentSRC, slot8CorrectSRC,
slot9Acc, slot9CurrentType, slot9CorrectType, slot9CurrentSRC, slot9CorrectSRC)
write_csv(check_answer_df, 'data/checkAnswer.csv')
# finding trial attempts by trial and subject
trialAttemptsByTrial <- check_answer_df %>%
group_by(subject, trialCount) %>%
summarize(n_attempts = max(trialAttempt))
included_sub_trials <- trialAttemptsByTrial %>%
filter(trialCount != 1 & n_attempts != 1) %>%
mutate(combined = paste(subject, trialCount, sep="_"))
#25 subjects usable
#list of column names for easy reference
correct_type_columns <- colnames(check_answer_df)[grepl("CorrectType", colnames(check_answer_df))]
correct_src_columns <- colnames(check_answer_df)[grepl("CorrectSRC", colnames(check_answer_df))]
current_src_columns <- colnames(check_answer_df)[grepl("CurrentSRC", colnames(check_answer_df))]
current_type_columns <- colnames(check_answer_df)[grepl("CurrentType", colnames(check_answer_df))]
acc_columns <- colnames(check_answer_df)[grepl("Acc", colnames(check_answer_df))]
#remove columns we don't need
new_check_answer_df <- check_answer_df  %>%
select(-correct_type_columns) %>%
select(-correct_src_columns) %>%
select(-RT) %>%
select(-nCorrect) %>%
filter(paste(subject, trialCount, sep="_") %in% included_sub_trials$combined)
slot_accuracies <- new_check_answer_df %>%
select(-current_src_columns) %>%
select(-current_type_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "acc") %>%
mutate(slot = gsub("Acc", "", slot))
slot_srcs <- new_check_answer_df %>%
select(-acc_columns) %>%
select(-current_type_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "src") %>%
mutate(slot = gsub("CurrentSRC", "", slot))
slot_threat_types <- new_check_answer_df %>%
select(-acc_columns) %>%
select(-current_src_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "threatType") %>%
mutate(slot = gsub("CurrentType", "", slot))
#join everything together
slot_images <- slot_srcs %>%
left_join(slot_threat_types, by=c("subject", "trialCount", "trialAttempt", "slot")) %>%
left_join(slot_accuracies, by=c("subject", "trialCount", "trialAttempt", "slot")) %>%
mutate(src = gsub(".jpg", "", src)) %>%
mutate(src = paste(src, "_", threatType, ".jpg", sep="")) %>%
select(-threatType)
# image_new_names = tibble(
#   src = unique(slot_images$src),
#   new_names = c(1:14) # <- this needs to be a handtyped list of e.g., snake.jpg, dog.jpg, etc, that corresponds to each row of images
# )
#
# slot_images <- slot_images %>%
#   left_join(image_new_names, by="src") %>%
#   mutate(src = new_names) %>%
#   select(-new_names)
slot_images
#SCORE 1
#next step: use the summarise function on slot_images to calculate, for each (group by) unique subject, trialCount, and src,
#the sum of correct placements (sum of acc column) across trial attempts.
sum_correct_trials_df <- slot_images %>%
group_by(subject, trialCount, src) %>%
summarise(sum_correct_trials = sum(acc))
#SCORE 2
first_correct_df <- slot_images %>%
# filter(acc == 1 & subject == "a2vo8c41jjiqy9" & trialCount == 2) %>%
filter(acc == 1) %>%
group_by(subject, trialCount, src) %>%
summarise(first_correct = first(trialAttempt))
#SCORE 3
first_correct_no_further_mistakes_df <- slot_images %>%
filter(acc == 1) %>%
group_by(subject, trialCount, src) %>%
mutate(trialAttempt_lag = lag(trialAttempt)) %>%
mutate(no_skip = ifelse(trialAttempt_lag == trialAttempt - 1, TRUE, FALSE),
no_skip = ifelse(is.na(no_skip), FALSE, no_skip)) %>%
filter(no_skip == FALSE) %>%
summarise(first_correct_no_further_mistakes = last(trialAttempt))
#join together all scores
scores <- sum_correct_trials_df %>%
left_join(first_correct_df, by = c("subject", "trialCount", "src")) %>%
left_join(first_correct_no_further_mistakes_df, by = c("subject", "trialCount", "src"))
write_csv(check_answer_df, 'data/dragTask/rawScores.csv')
#next step after that, group by subject and src (collapse across trials) to find the average accuracy score for each trial
average_scores <- scores %>%
group_by(subject, src) %>%
summarise(n_trials = n(),
score1 = mean(sum_correct_trials),
score2 = mean(first_correct),
score3 = mean(first_correct_no_further_mistakes))
write_csv(check_answer_df, 'data/dragTask/averageScores.csv')
#last step, group by just src to find mean accuracy score for each
src_average_scores <- average_scores %>%
group_by(src) %>%
summarise(scores1_mean = mean(score1),
score1_sem = std.error(score1),
scores2_mean = mean(score2),
score2_sem = std.error(score2),
scores3_mean = mean(score3),
score3_sem = std.error(score3)) %>%
mutate(condition = ifelse(grepl("threat", src), "threat", "neutral"))
write_csv(check_answer_df, 'data/dragTask/SRCaverageScores.csv')
ggplot(src_average_scores, aes(x = condition, y = scores3_mean, fill=condition)) +
geom_boxplot(alpha=0.5) +
geom_jitter()
#FIND HOW CLOSELY SCORES 1, 2, AND 3 ARE CORRELATED
average_scores
correlation_score_1_2 <- cor(average_scores$score1, average_scores$score2)
correlation_score_1_2
#-0.05104364 : very weak negative correlation between scores 1 & 2
linear_model_1_2 <- lm(score1 ~ score2, data = average_scores)
summary(linear_model_1_2)
correlation_score_2_3 <- cor(average_scores$score2, average_scores$score3)
correlation_score_2_3
#0.9582086 very strong positive correlation between scores 2&3 (makes sense as they are almost the same measure)
linear_model_2_3 <- lm(score2 ~ score3, data = average_scores)
summary(linear_model_2_3)
#correlation score 1 & 2 plot
ggplot(average_scores, aes(x = score1, y = score2, color=subject)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "Correlation between Score 1 and Score 2",
x = "Score 1",
y = "Score 2")
#correlation score 2 & 3 plot
ggplot(average_scores, aes(x = score2, y = score3)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "Correlation between Score 2 and Score 3",
x = "Score 2",
y = "Score 3")
#SCORE 2
first_correct_df <- slot_images %>%
# filter(acc == 1 & subject == "a2vo8c41jjiqy9" & trialCount == 2) %>%
filter(acc == 1) %>%
group_by(subject, trialCount, src) %>%
summarise(first_correct = first(trialAttempt))
first_correct_df
view(first_correct_df)
view(src_average_scores)
setwd("~/Documents/GitHub/anxiety_CM_thesis")
df <- read_csv('data/dragTask/SRCaverageScores.csv')
df
view(df)
setwd("~/Documents/GitHub/anxiety_CM_thesis")
df <- read_csv('data/dragTask/SRCaverageScores.csv')
df
setwd("~/Documents/GitHub/anxiety_CM_thesis")
this_df <- read_csv('data/dragTask/SRCaverageScores.csv')
this_df
setwd("~/Documents/GitHub/anxiety_CM_thesis")
this_df <- read_csv('data/dragTask/SRCaverageScores.csv')
this_df
view(this_df)
#last step, group by just src to find mean accuracy score for each
src_average_scores <- average_scores %>%
group_by(src) %>%
summarise(scores1_mean = mean(score1),
score1_sem = std.error(score1),
scores2_mean = mean(score2),
score2_sem = std.error(score2),
scores3_mean = mean(score3),
score3_sem = std.error(score3)) %>%
mutate(condition = ifelse(grepl("threat", src), "threat", "neutral"))
write_csv(check_answer_df, 'data/dragTask/SRCaverageScores.csv')
library(plotrix)
df <- read_csv('/Users/brookesevchik/Box/Data/Anxiety_Cognitive_Maps/all_participants/combinedData_Anxiety_Cognitive_Maps.csv')
check_answer_df <- df %>%
filter(sectionType == 'dragTaskCheckAnswerEvent') %>%
select(subject, trialCount, trialAttempt, RT, nCorrect, slot0Acc, slot0CurrentType, slot0CorrectType, slot0CurrentSRC, slot0CorrectSRC, slot1Acc,
slot1CurrentType, slot1CorrectType,slot1CurrentSRC, slot1CorrectSRC,
slot2Acc, slot2CurrentType, slot2CorrectType, slot2CurrentSRC, slot2CorrectSRC,
slot3Acc, slot3CurrentType, slot3CorrectType, slot3CurrentSRC, slot3CorrectSRC,
slot4Acc, slot4CurrentType, slot4CorrectType, slot4CurrentSRC, slot4CorrectSRC,
slot5Acc, slot5CurrentType, slot5CorrectType, slot5CurrentSRC, slot5CorrectSRC,
slot6Acc, slot6CurrentType, slot6CorrectType, slot6CurrentSRC, slot6CorrectSRC,
slot7Acc, slot7CurrentType, slot7CorrectType, slot7CurrentSRC, slot7CorrectSRC,
slot8Acc, slot8CurrentType, slot8CorrectType, slot8CurrentSRC, slot8CorrectSRC,
slot9Acc, slot9CurrentType, slot9CorrectType, slot9CurrentSRC, slot9CorrectSRC)
write_csv(check_answer_df, 'data/checkAnswer.csv')
# finding trial attempts by trial and subject
trialAttemptsByTrial <- check_answer_df %>%
group_by(subject, trialCount) %>%
summarize(n_attempts = max(trialAttempt))
included_sub_trials <- trialAttemptsByTrial %>%
filter(trialCount != 1 & n_attempts != 1) %>%
mutate(combined = paste(subject, trialCount, sep="_"))
#25 subjects usable
#list of column names for easy reference
correct_type_columns <- colnames(check_answer_df)[grepl("CorrectType", colnames(check_answer_df))]
correct_src_columns <- colnames(check_answer_df)[grepl("CorrectSRC", colnames(check_answer_df))]
current_src_columns <- colnames(check_answer_df)[grepl("CurrentSRC", colnames(check_answer_df))]
current_type_columns <- colnames(check_answer_df)[grepl("CurrentType", colnames(check_answer_df))]
acc_columns <- colnames(check_answer_df)[grepl("Acc", colnames(check_answer_df))]
#remove columns we don't need
new_check_answer_df <- check_answer_df  %>%
select(-correct_type_columns) %>%
select(-correct_src_columns) %>%
select(-RT) %>%
select(-nCorrect) %>%
filter(paste(subject, trialCount, sep="_") %in% included_sub_trials$combined)
slot_accuracies <- new_check_answer_df %>%
select(-current_src_columns) %>%
select(-current_type_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "acc") %>%
mutate(slot = gsub("Acc", "", slot))
slot_srcs <- new_check_answer_df %>%
select(-acc_columns) %>%
select(-current_type_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "src") %>%
mutate(slot = gsub("CurrentSRC", "", slot))
slot_threat_types <- new_check_answer_df %>%
select(-acc_columns) %>%
select(-current_src_columns) %>%
pivot_longer(cols = !c(subject, trialCount, trialAttempt), names_to = "slot", values_to = "threatType") %>%
mutate(slot = gsub("CurrentType", "", slot))
#join everything together
slot_images <- slot_srcs %>%
left_join(slot_threat_types, by=c("subject", "trialCount", "trialAttempt", "slot")) %>%
left_join(slot_accuracies, by=c("subject", "trialCount", "trialAttempt", "slot")) %>%
mutate(src = gsub(".jpg", "", src)) %>%
mutate(src = paste(src, "_", threatType, ".jpg", sep="")) %>%
select(-threatType)
# image_new_names = tibble(
#   src = unique(slot_images$src),
#   new_names = c(1:14) # <- this needs to be a handtyped list of e.g., snake.jpg, dog.jpg, etc, that corresponds to each row of images
# )
#
# slot_images <- slot_images %>%
#   left_join(image_new_names, by="src") %>%
#   mutate(src = new_names) %>%
#   select(-new_names)
slot_images
#SCORE 1
#next step: use the summarise function on slot_images to calculate, for each (group by) unique subject, trialCount, and src,
#the sum of correct placements (sum of acc column) across trial attempts.
sum_correct_trials_df <- slot_images %>%
group_by(subject, trialCount, src) %>%
summarise(sum_correct_trials = sum(acc))
#SCORE 2
first_correct_df <- slot_images %>%
# filter(acc == 1 & subject == "a2vo8c41jjiqy9" & trialCount == 2) %>%
filter(acc == 1) %>%
group_by(subject, trialCount, src) %>%
summarise(first_correct = first(trialAttempt))
#SCORE 3
first_correct_no_further_mistakes_df <- slot_images %>%
filter(acc == 1) %>%
group_by(subject, trialCount, src) %>%
mutate(trialAttempt_lag = lag(trialAttempt)) %>%
mutate(no_skip = ifelse(trialAttempt_lag == trialAttempt - 1, TRUE, FALSE),
no_skip = ifelse(is.na(no_skip), FALSE, no_skip)) %>%
filter(no_skip == FALSE) %>%
summarise(first_correct_no_further_mistakes = last(trialAttempt))
#join together all scores
scores <- sum_correct_trials_df %>%
left_join(first_correct_df, by = c("subject", "trialCount", "src")) %>%
left_join(first_correct_no_further_mistakes_df, by = c("subject", "trialCount", "src"))
write_csv(scores, 'data/dragTask/rawScores.csv')
#next step after that, group by subject and src (collapse across trials) to find the average accuracy score for each trial
average_scores <- scores %>%
group_by(subject, src) %>%
summarise(n_trials = n(),
score1 = mean(sum_correct_trials),
score2 = mean(first_correct),
score3 = mean(first_correct_no_further_mistakes))
write_csv(average_scores, 'data/dragTask/averageScores.csv')
#last step, group by just src to find mean accuracy score for each
src_average_scores <- average_scores %>%
group_by(src) %>%
summarise(scores1_mean = mean(score1),
score1_sem = std.error(score1),
scores2_mean = mean(score2),
score2_sem = std.error(score2),
scores3_mean = mean(score3),
score3_sem = std.error(score3)) %>%
mutate(condition = ifelse(grepl("threat", src), "threat", "neutral"))
write_csv(src_average_scores, 'data/dragTask/SRCaverageScores.csv')
ggplot(src_average_scores, aes(x = condition, y = scores3_mean, fill=condition)) +
geom_boxplot(alpha=0.5) +
geom_jitter()
#FIND HOW CLOSELY SCORES 1, 2, AND 3 ARE CORRELATED
average_scores
correlation_score_1_2 <- cor(average_scores$score1, average_scores$score2)
correlation_score_1_2
#-0.05104364 : very weak negative correlation between scores 1 & 2
linear_model_1_2 <- lm(score1 ~ score2, data = average_scores)
summary(linear_model_1_2)
correlation_score_2_3 <- cor(average_scores$score2, average_scores$score3)
correlation_score_2_3
#0.9582086 very strong positive correlation between scores 2&3 (makes sense as they are almost the same measure)
linear_model_2_3 <- lm(score2 ~ score3, data = average_scores)
summary(linear_model_2_3)
#correlation score 1 & 2 plot
ggplot(average_scores, aes(x = score1, y = score2, color=subject)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "Correlation between Score 1 and Score 2",
x = "Score 1",
y = "Score 2")
#correlation score 2 & 3 plot
ggplot(average_scores, aes(x = score2, y = score3)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "Correlation between Score 2 and Score 3",
x = "Score 2",
y = "Score 3")
setwd("~/Documents/GitHub/anxiety_CM_thesis")
df <- read_csv('data/dragTask/SRCaverageScores.csv')
df
score3_df <- df %>%
select(src, scores3_mean, score3_sem, condition)
score3_df
score3_avg <- score3_df %>%
group_by(condition)
score3_avg
library(dplyr)
# Group by the 'condition' column
grouped_df <- df_scores %>%
group_by(condition) %>%
summarise(
scores3_mean = mean(scores3_mean),
scores3_sem = mean(scores3_sem)
)
# Print the resulting data frame
print(grouped_df)
library(dplyr)
# Group by the 'condition' column
grouped_df <- score3_avg %>%
group_by(condition) %>%
summarise(
scores3_mean = mean(scores3_mean),
scores3_sem = mean(scores3_sem)
)
# Print the resulting data frame
print(grouped_df)
score3_avg <- score3_df %>%
group_by(condition) %>%
summarise(
scores3_mean = mean(scores3_mean),
scores3_sem = mean(scores3_sem)
)
score3_avg
setwd("~/Documents/GitHub/anxiety_CM_thesis")
df <- read_csv('data/dragTask/SRCaverageScores.csv')
score3_df <- df %>%
select(src, scores3_mean, score3_sem, condition)
score3_df
score3_avg <- score3_df %>%
group_by(condition) %>%
summarise(
scores3_mean = mean(scores3_mean),
scores3_sem = mean(scores3_sem)
)
score3_avg
score3_avg <- score3_df %>%
group_by(condition) %>%
summarise(
scores3_mean = mean(scores3_mean),
scores3_sem = mean(score3_sem)
)
score3_avg
t.test(score3_avg$scores3_mean ~ score3_avg$condition, mu = 0,
alternative = "greater",
paired = FALSE,
var.equal = FALSE,
conf.level = 0.95)
score3_df <- df %>%
select(src, scores3_mean, score3_sem, condition)
score3_df
t.test(score3_df$scores3_mean ~ score3_df$condition, mu = 0,
alternative = "greater",
paired = FALSE,
var.equal = FALSE,
conf.level = 0.95)
